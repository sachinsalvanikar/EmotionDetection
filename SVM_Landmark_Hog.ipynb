{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "train_folder = os.getcwd() + '/Dataset/Image_features/Training'\n",
    "validation_folder = os.getcwd() + '/Dataset/Image_features/PublicTest'\n",
    "test_folder = os.getcwd() + '/Dataset/Image_features/PrivateTest'\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    \n",
    "    data_dict = dict()\n",
    "    validation_dict = dict()\n",
    "    test_dict = dict()\n",
    "    \n",
    "     # load Train set \n",
    "    data_dict['X'] = np.load(train_folder + '/landmarks.npy')\n",
    "    data_dict['X'] = np.array([x.flatten() for x in data_dict['X']])\n",
    "    data_dict['X'] = np.concatenate((data_dict['X'], np.load(train_folder + '/hog_features.npy')), axis=1)\n",
    "    data_dict['Y'] = np.load(train_folder + '/labels.npy')\n",
    "    \n",
    "     # load validation set \n",
    "    validation_dict['X'] = np.load(validation_folder + '/landmarks.npy')\n",
    "    validation_dict['X'] = np.array([x.flatten() for x in validation_dict['X']])\n",
    "    validation_dict['X'] = np.concatenate((validation_dict['X'], np.load(validation_folder + '/hog_features.npy')), axis=1)\n",
    "    validation_dict['Y'] = np.load(validation_folder + '/labels.npy')\n",
    "    \n",
    "    # load train set\n",
    "    test_dict['X'] = np.load(test_folder + '/landmarks.npy')\n",
    "    test_dict['X'] = np.array([x.flatten() for x in test_dict['X']])\n",
    "    test_dict['X'] = np.concatenate((test_dict['X'], np.load(test_folder + '/hog_features.npy')), axis=1)\n",
    "    test_dict['Y'] = np.load(test_folder + '/labels.npy')\n",
    "    np.save(test_folder + \"/lab.npy\", test_dict['Y'])\n",
    "    return data_dict, validation_dict, test_dict\n",
    "    #return Train, Validation, Test Set \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "if sys.version_info >= (3, 0):\n",
    "        import _pickle as cPickle\n",
    "else:\n",
    "        import cPickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Hyperparameter\n",
    "\n",
    "random_state = 0\n",
    "epochs = 10000\n",
    "epochs_during_hyperopt = 500\n",
    "kernel = 'rbf'  # 'rbf', 'linear', 'poly' or 'sigmoid'\n",
    "decision_function = 'ovr'  # 'ovo' for OneVsOne and 'ovr' for OneVsRest'\n",
    "features = \"landmarks_and_hog\" # \"landmarks\" or \"hog\" or \"landmarks_and_hog\"\n",
    "gamma = 'auto' # use a float number or 'auto' \n",
    "\n",
    "\n",
    "data, validation, test = load_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 2728)\n",
      "(28709,)\n"
     ]
    }
   ],
   "source": [
    "#Check the shape \n",
    "print(data['X'].shape)\n",
    "print(data['Y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model...\n",
      "start training...\n",
      "--\n",
      "Training samples: 28709\n",
      "Validation samples: 3589\n",
      "--\n",
      "training time = 11472.8 sec\n"
     ]
    }
   ],
   "source": [
    "# Building Model\n",
    "print( \"building model...\")\n",
    "model = SVC(random_state=random_state, max_iter=epochs, kernel=kernel, decision_function_shape=decision_function, gamma=gamma)\n",
    "print( \"start training...\")\n",
    "print( \"--\")\n",
    "print( \"Training samples: {}\".format(len(data['Y'])))\n",
    "print( \"Validation samples: {}\".format(len(validation['Y'])))\n",
    "print( \"--\")\n",
    "start_time = time.time()\n",
    "model.fit(data['X'], data['Y'])\n",
    "training_time = time.time() - start_time\n",
    "print( \"training time = {0:.1f} sec\".format(training_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, Y):\n",
    "        predicted_Y = model.predict(X)\n",
    "        accuracy = accuracy_score(Y, predicted_Y)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n",
      "  - validation accuracy = 49.7\n"
     ]
    }
   ],
   "source": [
    "print( \"evaluating...\")\n",
    "#validation_accuracy = model.evaluate(validation['X'], validation['Y'],verbose=0)\n",
    "validation_accuracy = evaluate(model, validation['X'],  validation['Y'])\n",
    "print( \"  - validation accuracy = {0:.1f}\".format(validation_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - test accuracy = 50.5\n",
      "  - evalution time = 15517.8 sec\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = evaluate(model, test['X'], test['Y'])\n",
    "print( \"  - test accuracy = {0:.1f}\".format(test_accuracy*100))\n",
    "print( \"  - evalution time = {0:.1f} sec\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVMModel.joblib']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# once We will save this trained model then we can reuse it on other system.\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(model, 'SVMModel.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
